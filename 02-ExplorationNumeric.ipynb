{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization\n",
    "Now that we learned how pandas data selection works, let us investigate the different features visually. For that we use the Python package `matplotlib`, which provides versatile visualization capabilities. Luckily, pandas wraps calls to matplotlib neatly and has a great [documentation](https://pandas.pydata.org/docs/user_guide/visualization.html) about it.\n",
    "\n",
    "Let us start by visualizing the tabular data we retrieved above. A handy way to do this is by using boxplots. Let us first make some configurations to make the plots look beautiful in jupyter and then actually plot the boxes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline\n",
    "# Change default size of figures:\n",
    "plt.rcParams[\"figure.figsize\"] = (12,7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let us do a box plot by simply selecting a columns and call [`.plot.box()`](https://pandas.pydata.org/docs/user_guide/visualization.html#box-plots) on it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = df[\"Age\"].plot.box()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A box plot can be handy to see the distribution over one variable. It gives us the following information:\n",
    "\n",
    "- The lower line indicates the 1% quartile, that is the value at or below which 1% of the data lie.\n",
    "- The lower boundry of the box indicates the 25% quartile.\n",
    "- The green line indicates the average\n",
    "- The upper boundry of the box indicates the 75% quartile.\n",
    "- The upper line indicates the 99% quartile.\n",
    "- The dots above this line are individual values that are higher than the 99% quartile They are often consider outliers.\n",
    "\n",
    "\n",
    "We however, want to see how variables relate to our target, did the person survive or not. For that alpha blended histogramms or stacked bar charts come in handy. But pandas provides way more options to plot data, e.g. [histograms](https://pandas.pydata.org/docs/user_guide/visualization.html#histograms).\n",
    "\n",
    "To try this, first plot a histogramm for one of the columns. Then (in a new cell) plot two of them when by filtering for all survivours and one for all others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.title(\"Age\")\n",
    "df.loc[df[\"Survived\"] == True, \"Age\"].plot.hist(alpha=0.5, label=\"Survived\", bins=20)\n",
    "df.loc[df[\"Survived\"] == False, \"Age\"].plot.hist(alpha=0.5, label=\"Deceased\", bins=20)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you have categorical values, stacked bar charts might be the right way to go.\n",
    "\n",
    "For this, we unluckily have to transform our data a bit. This can be done using grouping. Pandas essentially allows you to split your dataframe up into multiple once. Each one having the same values over one or multiple columns.\n",
    "\n",
    "Let us [group them by](https://pandas.pydata.org/pandas-docs/stable/user_guide/groupby.html#splitting-an-object-into-groups) the column we want to plot (e.g. `\"Pclass\"`) and the target `\"Survived\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = df.groupby([\"Pclass\", \"Survived\"])\n",
    "grouped.groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped.get_group((1,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we count the occurence of the `\"Pclass\"` for each combindation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass_counts = grouped[\"Pclass\"].count()\n",
    "pclass_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we move the `\"Survived\"` index to a new column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass_counts = pclass_counts.unstack(\"Survived\")\n",
    "pclass_counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This we can then plot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pclass_counts.plot.bar(stacked=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience reasons we should wrap this into a function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_stacked_bar_chart(df: pd.DataFrame, x_axis: str, stack_dimension: str):\n",
    "    bar_dataframe = df.groupby([x_axis, stack_dimension])[x_axis].count().unstack(stack_dimension).fillna(0)\n",
    "    bar_dataframe.plot.bar(stacked = True)\n",
    "    plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_stacked_bar_chart(df, \"Pclass\", \"Survived\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given these two option, investigate the remaining columns (`[\"Fare\", \"SibSp\", \"Parch\"]`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To already get an intuition in how the data correlate with our target, let us as well look at the correlation matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_features = [\"Age\", \"SibSp\", \"Parch\", \"Fare\"]\n",
    "df[[*numeric_features, \"Survived\"]].corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an intuition for our data, let us continue by [training a machine learning algorithm](./03-SklearnIntroduction.ipynb) with them."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
